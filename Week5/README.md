# Micro Speech CASA

In the week 5 worked example during the lecture we will be using the `micro_speech` example from the Harvard TinyML library: in Arduino IDE go to `File > Examples > Harvard_TinyMLx > micro_speech`

In the Tutorial you will be developing your own wake word sketch using [Edge Impulse](www.edgeimpulse.com). We will use their [responding to your voice](https://docs.edgeimpulse.com/docs/tutorials/end-to-end-tutorials/responding-to-your-voice) tutorial as the basis for creating your first project. Their tutorial walks through the initial set-up required to connect your Arduino to their platform.

This folder also contains a section called `helper` which has a simple Python sketch to help you listen to some of the source data you are using - it can automatically play through a folder of 1 second audio clips.

The `pre2023` folder relates to previous workshops used on the course - they no longer work since they were basd on TF1 which has been deprecated in Google Colab, but are kept here for reference in case you want to use them as a starting point to re-implement.

~~Two sections in this folder:~~
    
- ~~this root folder contains the prebuilt Arduino example (Ch7 TinyML book)~~
    
- ~~the training folder contains a second section with training notebook (Ch8 TinyML book)~~

~~Arduino example based on the TensorFlow [micro_speech](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/micro_speech) example described in Ch.7 of TinyML book and in the "examples" folder of Arduino when the tensorflow lite library is installed.~~

Video below shows an example deployed on Arduino Nano.

[![Watch the video](https://img.youtube.com/vi/oKr7YvlxUKQ/maxresdefault.jpg)](https://youtu.be/oKr7YvlxUKQ)
